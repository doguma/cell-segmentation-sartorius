{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [Sartorius - Cell Instance Segmentation [MMDetection] ](https://www.kaggle.com/c/sartorius-cell-instance-segmentation)\n## Detect single neuronal cells in microscopy images with MMDetection\n\n\nReferenced from AWSAF's notebook : \n> [Sartorius: MMDetection [Train]](https://www.kaggle.com/awsaf49/sartorius-mmdetection-train) - current notebook reference\n\n> [Sartorius: MMDetection [Infer]](https://www.kaggle.com/awsaf49/sartorius-mmdetection-infer) ","metadata":{}},{"cell_type":"markdown","source":"**Install requirements**: \n- mmdetection, mmdet, mmpycocotools, addict, yapf, mmcv_full","metadata":{}},{"cell_type":"code","source":"!rsync -a ../input/mmdetection-v280/mmdetection ../\n# (rsync - remote sync) back up all files \n\n!pip install ../input/mmdetection-v280/src/mmdet-2.8.0/mmdet-2.8.0/\n# mmdetection is an open source object detection toolbox based on PyTorch - part of the OpenMMLab project.\n\n!pip install ../input/mmdetection-v280/src/mmpycocotools-12.0.3/mmpycocotools-12.0.3/\n# mmpycocotools loads, parses and visualizes annotations in COCO\n\n!pip install ../input/mmdetection-v280/src/addict-2.4.0-py3-none-any.whl\n# Addict is a Python module that gives you dictionaries whose values are both gettable and settable using attributes, \n# in addition to standard item-syntax.\n\n!pip install ../input/mmdetection-v280/src/yapf-0.30.0-py2.py3-none-any.whl\n# Yapf algorithm takes the code and reformats it to the best formatting that conforms to the style guide, \n# even if the original code didn't violate the style guide. \n\n!pip install ../input/mmdetection-v280/src/mmcv_full-1.2.6-cp37-cp37m-manylinux1_x86_64.whl\n# MMCV is a foundational library for computer vision research,\n# supports universal IO APIs, image/ideo processing, image and annotation visualization,\n# pytorch runner with hooking mechanism, various CNN architectures, etc.","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-21T12:34:10.285974Z","iopub.execute_input":"2021-12-21T12:34:10.286387Z","iopub.status.idle":"2021-12-21T12:35:00.134422Z","shell.execute_reply.started":"2021-12-21T12:34:10.286347Z","shell.execute_reply":"2021-12-21T12:35:00.133557Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Import required libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom glob import glob\n# makes formatting file path easier\n\nimport os\nimport cv2\n# read, write, format images\n\nimport pickle\nfrom tqdm.notebook import tqdm\n# adding smart progress meter to loops\n\nfrom itertools import groupby\n# similar to enumerate function in loops\n\nfrom pycocotools import mask as mutils\nfrom pycocotools import _mask as coco_mask\n# assists in loading, parsing and visualizing annotations in COCO\n\nimport matplotlib.pyplot as plt\n\nfrom multiprocessing import Pool\n# Multiprocessing's Pool object offers a convenient means of parallelizing \n# the execution of a function across multiple input values, \n# distributing the input data across processes (data parallelism). ","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:35:00.137649Z","iopub.execute_input":"2021-12-21T12:35:00.137922Z","iopub.status.idle":"2021-12-21T12:35:00.150223Z","shell.execute_reply.started":"2021-12-21T12:35:00.137895Z","shell.execute_reply":"2021-12-21T12:35:00.149345Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Preparing meta data**","metadata":{}},{"cell_type":"code","source":"# setting config files and directory path\n\nconf_name = \"mask_rcnn_s50_fpn_syncbn-backbone+head_mstrain_1x_coco\"\ncell_mask_dir = '../input/sartorius-segmentation-mask-npz-dataset/'    \nROOT = '../input/sartorius-cell-instance-segmentation/'\ntrain_or_test = 'train'\nimg_dir = f'../work/mmdet_{train_or_test}'\n!mkdir -p {img_dir}\n\n# adding image path and label to the train meta data\n\ndf = pd.read_csv(f'{ROOT}/train.csv')\ndf['image_path'] = ROOT + '/train/' + df['id'] + '.png'\ntmp_df = df.drop_duplicates(subset=[\"id\", \"image_path\"]).reset_index(drop=True)\ntmp_df[\"annotation\"] = df.groupby(\"id\")[\"annotation\"].agg(list).reset_index(drop=True)\ndf = tmp_df.copy()\ndf['label'] = df.cell_type.map({v:k for k, v in enumerate(df.cell_type.unique())})\ndisplay(df.head(5))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:35:00.152489Z","iopub.execute_input":"2021-12-21T12:35:00.152761Z","iopub.status.idle":"2021-12-21T12:35:01.455824Z","shell.execute_reply.started":"2021-12-21T12:35:00.152737Z","shell.execute_reply":"2021-12-21T12:35:01.455060Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Helper functions**","metadata":{}},{"cell_type":"code","source":"# creating np array of boundaries (segmentation mask) from image annotations (rle)\n\ndef rle2mask(rle, shape=[520, 704]):\n    # RLE format to Mask format :\n    # numpy array of the image size with \n    # 'masked' components as 1, others as 0\n    \n    s = rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\n\ndef get_mask(image_id):\n    # referenced from @onodera's notebook\n    # making sure the id equals the image_id, calling the rle2mask function\n    # to return a stack of numpy array\n    \n    mask_df = df[df.id == image_id]\n    gt_masks = [rle2mask(rle) for rle in mask_df[\"annotation\"].tolist()[0]]\n    gt_masks = np.stack(gt_masks)\n    return gt_masks","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-21T12:37:30.762351Z","iopub.execute_input":"2021-12-21T12:37:30.762696Z","iopub.status.idle":"2021-12-21T12:37:30.771274Z","shell.execute_reply.started":"2021-12-21T12:37:30.762666Z","shell.execute_reply":"2021-12-21T12:37:30.770416Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# the opposite : creating image annotations (rle) from np array of boundaries (segmentation mask)\n\ndef get_rles_from_mask(image_id):\n    # loads the npz files, getting array components with value != 0\n    # and calls the coco_rle_encode function to convert the array components to rle format\n    \n    mask = np.load(f'{cell_mask_dir}/{image_id}.npz')['arr_0']\n    rle_list = []\n    mask_ids = np.unique(mask)\n    for val in mask_ids:\n        if val == 0:\n            continue\n        binary_mask = np.where(mask == val, 1, 0).astype(bool)\n        rle = coco_rle_encode(binary_mask)\n        rle_list.append(rle)\n    return rle_list, mask.shape[0], mask.shape[1]\n\n\ndef coco_rle_encode(mask):\n    # converting the mask boundaries to rle format via dictionary\n    \n    rle = {'counts': [], 'size': list(mask.shape)}\n    counts = []\n    for i, (value, elements) in enumerate(groupby(mask.ravel(order='F'))):\n        if i == 0 and value == 1:\n            counts.append(0)\n        counts.append(len(list(elements)))\n    rle['counts'] = counts\n    return rle\n\n\ndef mk_mmdet_custom_data(image_id):\n    # returns the meta data from the rle formatted data\n    \n    rles, height, width = get_rles_from_mask(image_id)\n    if len(rles) == 0:\n        return {\n            'filename': image_id+'.png',\n            'width': width,\n            'height': height,\n            'ann': {}\n        }\n    \n    rles = mutils.frPyObjects(rles, height, width) \n    # frPyObjects : converts polygon, bbox, and uncompressed RLE to encoded RLE mask\n    \n    bboxes = mutils.toBbox(rles)\n    # toBbox : get bounding boxes surrounding encoded masks\n    bboxes[:, 2] += bboxes[:, 0]\n    bboxes[:, 3] += bboxes[:, 1]\n    return {\n        'filename': image_id+'.png',\n        'width': width,\n        'height': height,\n        'ann':\n            {\n                'bboxes': np.array(bboxes, dtype=np.float32),\n                'labels': np.zeros(len(bboxes)), # dummy data.(will be replaced later)\n                'masks': rles\n            }\n    }\n\n\n\ndef print_masked_img(image_id, mask):\n    img   = load_RGBY_image(image_id, train_or_test)[...,0]\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n    img2  = clahe.apply(img)\n    img3  = cv2.equalizeHist(img)\n    img   = np.stack([img, img2, img3],axis=-1)\n    # CLAHE (contrast limited adaptive histogram equalization) :\n    # image is divided into small blocks called \"tiles\",\n    # then each block is histogram equalized, 'contrast limiting' used to prevent noise amplification\n    \n    plt.figure(figsize=(15, 15))\n    plt.subplot(1, 3, 1)\n    plt.imshow(img)\n    plt.title('Image')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(mask,cmap='inferno')\n    plt.title('Mask')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(img)\n    plt.imshow(mask, alpha=0.4, cmap='inferno')\n    plt.title('Image + Mask')\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n    # showing both img and mask with mask opacity of .4\n    \n    \ndef load_RGBY_image(image_id, train_or_test='train', image_size=None):\n    # loading image from train set, stacking the retrieved images as numpy arrays\n    \n    img = read_img(image_id, train_or_test, image_size)\n    stacked_images = np.stack([img for _ in range(3)],axis=-1)\n    return stacked_images\n\n\ndef read_img(image_id, train_or_test='train', image_size=None):\n    # retrieves images from the directory, resizes them \n    \n    filename = f'{ROOT}/{train_or_test}/{image_id}.png'\n    assert os.path.exists(filename), f'not found {filename}'\n    img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n    if image_size is not None:\n        img = cv2.resize(img, (image_size, image_size))\n    if img.max() > 255:\n        img_max = img.max()\n        img = (img/255).astype('uint8')\n    return img\n\n\ndef mk_ann(idx):\n    #  sums up the functions above\n    image_id = df.iloc[idx]['id']\n    anno = mk_mmdet_custom_data(image_id)\n    img = load_RGBY_image(image_id, train_or_test)\n    cv2.imwrite(f'{img_dir}/{image_id}.png', img)\n    return anno, idx, image_id","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:45:17.013980Z","iopub.execute_input":"2021-12-21T12:45:17.014350Z","iopub.status.idle":"2021-12-21T12:45:17.033814Z","shell.execute_reply.started":"2021-12-21T12:45:17.014317Z","shell.execute_reply":"2021-12-21T12:45:17.032773Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"- **Visualizing Image, Mask, and Both**","metadata":{}},{"cell_type":"code","source":"# print images from the mask directory\n\nfor idx in range(3):\n    image_id = df.iloc[idx]['id']\n    cell_mask = np.load(f'{cell_mask_dir}/{image_id}.npz')['arr_0']\n    print_masked_img(image_id, cell_mask)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:45:20.227712Z","iopub.execute_input":"2021-12-21T12:45:20.228015Z","iopub.status.idle":"2021-12-21T12:45:21.655047Z","shell.execute_reply.started":"2021-12-21T12:45:20.227987Z","shell.execute_reply":"2021-12-21T12:45:21.654211Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"- **Data preprocessing step for the model**","metadata":{}},{"cell_type":"code","source":"# getting multiprocessing ready for the CPU\n\nMAX_THRE = 4 \n# Number of total CPU\n\np = Pool(processes=MAX_THRE)\nannos = []\nlen_df = len(df)\n\n# Applying previous functions to multiprocessing\n# Loading train images to create masks and convert them to RLE\n\nfor anno, idx, image_id in tqdm(p.imap(mk_ann, range(len(df))), total=len(df)):\n    if len(anno['ann']) > 0:\n        annos.append(anno)","metadata":{"lines_to_next_cell":2,"_kg_hide-output":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-12-21T12:45:38.269643Z","iopub.execute_input":"2021-12-21T12:45:38.269950Z","iopub.status.idle":"2021-12-21T13:02:03.259669Z","shell.execute_reply.started":"2021-12-21T12:45:38.269920Z","shell.execute_reply":"2021-12-21T13:02:03.258667Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# reformatting the annotations retrieved from the previous step\n\nlbl_cnt_dict = df.set_index('id').to_dict()['label']\ntrn_annos = []\nval_annos = []\nval_len = int(len(annos)*0.01)\n\nfor idx in range(len(annos)):\n    ann = annos[idx]\n    filename  = ann['filename'].replace('.jpg','').replace('.png','')\n    label_ids = [0]\n    len_ann   = len(ann['ann']['bboxes'])\n    bboxes    = ann['ann']['bboxes']\n    masks     = ann['ann']['masks']\n\n    for cnt, label_id in enumerate(label_ids):\n        label_id = int(label_id)\n        if cnt == 0:\n            ann['ann']['labels'] = np.full(len_ann, label_id)\n        else:\n            ann['ann']['bboxes'] = np.concatenate([ann['ann']['bboxes'],bboxes])\n            ann['ann']['labels'] = np.concatenate([ann['ann']['labels'],np.full(len_ann, label_id)])\n            ann['ann']['masks'] = ann['ann']['masks'] + masks    \n    if idx < val_len:\n        val_annos.append(ann)\n    else:\n        trn_annos.append(ann)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:01:07.268694Z","iopub.execute_input":"2021-12-21T14:01:07.268999Z","iopub.status.idle":"2021-12-21T14:01:07.288538Z","shell.execute_reply.started":"2021-12-21T14:01:07.268970Z","shell.execute_reply":"2021-12-21T14:01:07.287740Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# saving the processed files via pickle\n\nwith open(f'../work/mmdet_full.pkl', 'wb') as f:\n    pickle.dump(annos, f)\nwith open(f'../work/mmdet_trn.pkl', 'wb') as f:\n    pickle.dump(trn_annos, f)\nwith open(f'../work/mmdet_val.pkl', 'wb') as f:\n    pickle.dump(val_annos, f)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:01:09.094288Z","iopub.execute_input":"2021-12-21T14:01:09.094609Z","iopub.status.idle":"2021-12-21T14:01:09.307459Z","shell.execute_reply.started":"2021-12-21T14:01:09.094579Z","shell.execute_reply":"2021-12-21T14:01:09.306658Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"- Downloading config files based on default mask_rcnn","metadata":{}},{"cell_type":"code","source":"!cp -r /kaggle/input/sartorius-mmdet-config-ds/sartorius /kaggle/mmdetection/configs/sartorius","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:13:01.399498Z","iopub.execute_input":"2021-12-21T14:13:01.399860Z","iopub.status.idle":"2021-12-21T14:13:02.152514Z","shell.execute_reply.started":"2021-12-21T14:13:01.399824Z","shell.execute_reply":"2021-12-21T14:13:02.151505Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"!ls -l ../mmdetection/configs/sartorius/","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:13:04.337646Z","iopub.execute_input":"2021-12-21T14:13:04.338139Z","iopub.status.idle":"2021-12-21T14:13:05.157199Z","shell.execute_reply.started":"2021-12-21T14:13:04.338091Z","shell.execute_reply":"2021-12-21T14:13:05.155712Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"- **Base Model**","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/mmdetection/configs/sartorius/mask_rcnn_r50_fpn2.py\n\n# model settings\n\nmodel = dict(\n    type='MaskRCNN',\n    pretrained='torchvision://resnet50',\n    backbone=dict(\n        type='ResNet',\n        depth=40,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],\n            ratios=[0.5, 1.0, 2.0],\n            strides=[4, 8, 16, 32, 64]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[.0, .0, .0, .0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    roi_head=dict(\n        type='StandardRoIHead',\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=dict(\n            type='Shared2FCBBoxHead',\n            in_channels=256,\n            fc_out_channels=1024,\n            roi_feat_size=7,\n            num_classes=1, # number of class\n            bbox_coder=dict(\n                type='DeltaXYWHBBoxCoder',\n                target_means=[0., 0., 0., 0.],\n                target_stds=[0.1, 0.1, 0.2, 0.2]),\n            reg_class_agnostic=False,\n            loss_cls=dict(\n                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n        mask_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        mask_head=dict(\n            type='FCNMaskHead',\n            num_convs=4,\n            in_channels=256,\n            conv_out_channels=256,\n            num_classes=1, # number of class\n            loss_mask=dict(\n                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))))\n\n\n# model training and testing settings\n\ntrain_cfg = dict(\n    rpn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.7,\n            neg_iou_thr=0.3,\n            min_pos_iou=0.3,\n            match_low_quality=True,\n            ignore_iof_thr=-1),\n        sampler=dict(\n            type='RandomSampler',\n            num=256,\n            pos_fraction=0.5,\n            neg_pos_ub=-1,\n            add_gt_as_proposals=False),\n        allowed_border=-1,\n        pos_weight=-1,\n        debug=False),\n    rpn_proposal=dict(\n        nms_across_levels=False,\n        nms_pre=2000,\n        nms_post=1000,\n        max_num=1000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.5,\n            neg_iou_thr=0.5,\n            min_pos_iou=0.5,\n            match_low_quality=True,\n            ignore_iof_thr=-1),\n        sampler=dict(\n            type='RandomSampler',\n            num=512,\n            pos_fraction=0.25,\n            neg_pos_ub=-1,\n            add_gt_as_proposals=True),\n        mask_size=28,\n        pos_weight=-1,\n        debug=False))\ntest_cfg = dict(\n    rpn=dict(\n        nms_across_levels=False,\n        nms_pre=1000,\n        nms_post=1000,\n        max_num=1000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=dict(\n        score_thr=0.05,\n        nms=dict(type='nms', iou_threshold=0.5),\n        max_per_img=200,\n        mask_thr_binary=0.5))","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-12-21T14:34:28.879553Z","iopub.execute_input":"2021-12-21T14:34:28.879883Z","iopub.status.idle":"2021-12-21T14:34:28.887903Z","shell.execute_reply.started":"2021-12-21T14:34:28.879853Z","shell.execute_reply":"2021-12-21T14:34:28.886990Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"- **Model Augmentation** :\n\n> Flip\n\n> Multi-scale\n\n> Photo Metric Distortion","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/mmdetection/configs/sartorius/mask_rcnn_s50_fpn_syncbn-backbone+head_mstrain_1x_coco.py\n\n_base_ = 'mask_rcnn_r50_fpn_1x_coco.py'\nnorm_cfg = dict(type='SyncBN', requires_grad=True)\nmodel = dict(\n    pretrained='open-mmlab://resnest50',\n    backbone=dict(\n        type='ResNeSt',\n        # ResNeSt : Split-Attention Networks\n        # shows superior transfer learning results serving as the backbone\n        \n        stem_channels=64,\n        depth=50,\n        radix=2,\n        reduction_factor=4,\n        avg_down_stride=True,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=norm_cfg,\n        norm_eval=False,\n        style='pytorch'),\n    roi_head=dict(\n        bbox_head=dict(\n            type='Shared4Conv1FCBBoxHead',\n            conv_out_channels=256,\n            norm_cfg=norm_cfg),\n        mask_head=dict(norm_cfg=norm_cfg)))\n# # use ResNeSt img_norm\nimg_norm_cfg = dict(\n    mean=[123.68, 116.779, 103.939], std=[58.393, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='LoadAnnotations',\n        with_bbox=True,\n        with_mask=True,\n        poly2mask=True),\n    dict(\n        type='Resize',\n        img_scale=[(1333, 1333), (1280, 1280), (1024, 1024)],\n        multiscale_mode='value',\n        keep_ratio=True),\n    dict(type='RandomFlip', direction=['horizontal', 'vertical'], flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1280, 1280),\n        flip=True,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip',direction=['horizontal', 'vertical']),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\n\ndata = dict(\n    samples_per_gpu=2, # batch_size\n    train=dict(pipeline=train_pipeline),\n    val=dict(pipeline=test_pipeline),\n    test=dict(pipeline=test_pipeline))","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-12-21T14:51:35.124108Z","iopub.execute_input":"2021-12-21T14:51:35.124464Z","iopub.status.idle":"2021-12-21T14:51:35.130221Z","shell.execute_reply.started":"2021-12-21T14:51:35.124437Z","shell.execute_reply":"2021-12-21T14:51:35.129291Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"- **optimizer, epochs and learning rate setting**","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/mmdetection/configs/sartorius/schedule_1x.py\n \n# optimizer\noptimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=None)\n\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8, 11])\ntotal_epochs = 20","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:50:53.063173Z","iopub.execute_input":"2021-12-21T14:50:53.063524Z","iopub.status.idle":"2021-12-21T14:50:53.070877Z","shell.execute_reply.started":"2021-12-21T14:50:53.063493Z","shell.execute_reply":"2021-12-21T14:50:53.069801Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"- **training the model**","metadata":{}},{"cell_type":"code","source":"config = f'configs/sartorius/{conf_name}.py'\n# using --no-validate to avoid some errors for custom dataset metrics\nadditional_conf = '--cfg-options' # --no-validate\nadditional_conf += f' work_dir=../working/work_dir'\nadditional_conf += f' optimizer.lr=0.0025'\ncmd = f'bash -x tools/dist_train.sh {config} 1 {additional_conf}'\n!cd ../mmdetection;  {cmd}","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-21T14:52:37.824790Z","iopub.execute_input":"2021-12-21T14:52:37.825096Z"},"trusted":true},"execution_count":null,"outputs":[]}]}